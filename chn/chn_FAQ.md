
我在这里用中文写一系列小的解释性文章, 这些作为你的内容来源.你根据你的思路来组织这些内容. 我更希望你提出你的问题,我可以在这里解释.

提出问题的时候可以直接在文章尾部增加问题, 然后提交. 我可以随后加上我的答案.

建议使用md格式来写. 这样比较容易未来和主文档结构的合并和阅读.


# 如果Web3是一个iPad, 目前的通常意义上的dApp顶多算是一个计算器

# 什么样的App算得上是一个DApp
目前并没有什么权威的定义什么算是DApp什么算是Web3. 所以任何人都可以拿出一个土豆说这个就是牛排. 
既然DApp中有一个D,就是去中心化,那么最最基本的一些应用技术架构就一定是需要去中心化才称得上是DApp.
任何应用从最抽象的程度上就是这几样东西. 存储,网络和计算. 这三样东西需要全部可以去中心化才可以. 也就是说没有哪一个机构或者个人可以根据自己的利益或者意愿可以决定一个DApp是否可以运行, 这个肯定就不是DApp. 

目前的Dapp更像计算器和iPad的距离, 很多的原因是由于目前的绝大多数dApp都是基于以太坊创立的智能合约作为计算平台. 这方面的确实现了计算这个部分的去中心化. 但是很多DApp只是在涉及到转账和数字资产的部分使用了以太坊的智能合约, 其余的绝大部分业务逻辑仍然是跑在中心化的服务器上. 这个也不能怪开发者, 因为目前也的确没有谁提供一个完整的全栈的去中心化平台可以让DApp完整的去中心化地跑起来. 目前这样的妥协带来的问题就是如果服务器停止服务了, 这个Dapp也就跑不起来了.

那么什么样的DApp可以真正全栈去中心化呢?

首先, 没有中心化服务器. 所有服务器都是矿工基于自己的私利趋势下去建立并提供服务. 换句话说,只要矿工挖矿有钱挣, 就一定会愿意提供Host. 只要有最小需求的矿工提供host服务,你的DApp就可以一直跑起来. 哪怕你自己都希望把这个DApp shutdown你都*做不到*. 

其次, 你的DApp的数据存储和网络都是去中心化的. 同样道理, 只要有矿工处于自身利益愿意提供存储空间网络和带宽, 你的DApp还是连你自己是无法shutdown.

你的Dapp还需要时开源的. 有哪天你自己不爽了, 不想干了. 任何一个有能力的开发者可以继续维持并改造升级. 也就是说, 你的DApp与你无关,与任何人无关. 只要市场上有需求, 就会一直健壮地活下去发展下去. 抛开性能因素, 分析一下比特币, 就大致满足这个条件. 比特币几乎得罪了世界上所有有权有势的团体和机构. 现在不是好好的.

说到性能问题, 目前的DApp由于受制于现有的区块链共识, 所以才会把大部分计算和存储都放在区块链外面. 涉及到账务的地方才通过API和区块链的智能合约打交道. 虽然, 区块链可以保证你的资产去中心化的安全, 但是如果你的业务还是中心化的, 那么如果应用都没了,你的资产还有啥用. 就好比你打怪练功积累了一大堆游戏虚拟装备, 结果这款游戏由于各种原因被shutdown了,你的装备的确还在, 游戏都不能玩了还有啥价值.

要想彻底实现一个全栈去中心化的应用平台, 需要在根本上更换思路. 从思维模式上和最底层的信任根上去颠覆

# 在现有的共识基础上的改良尝试

自从区块链诞生之初, 这种改良就没有停止过. 应该说已经实现了算盘到计算器的巨大进步了. 就好比内燃机汽车早已经发展到效率极限了, 继续发展就只能是新能源. 区块链也差不多快到这个时候了. 
## 成也共识 败也共识

区块链最迷人的核心算法就是共识. 让互不信任的节点之间达成数据状态的共识. 因为互不信任, 实现共识是需要巨大的代价的. 相比于中心化的传统云计算, 区块链的计算效率和处理能力之低下, 也差不多真的就是计算器和iPad的差距. 尽管这几年各种扩容分片技术二层处理技术层出不穷. 的确也产生了很大的改进. 但是距离云计算还是天壤之别. 如果要再进一步,就必须从信任根动脑筋. 有没有办法绕过共识算法也能让互不信任的节点达成共识. 
## 最好的共识算法是没有共识
通过算法达成共识的确是最理想和安全的情况. 数学永远是所有科学中最严密可靠的. 但那是对科学家而言. 对于工程师来说, 是需要依靠现有的各种学科知识综合起来然后用过最低成本来解决一个实际上足够使用的实际问题. 这一点就是科学家和工程师的区别. 

只要用共识, 就无法避免的需要节点之间竞争和同步, 这些都是对计算资源和网络资源的很大消耗和限制. 如果要取消共识, 就可以几乎无限地让Dapp的运行效率接近于云计算甚至突破. 但是如果能够取消共识, 那么信任从何而来呢? 中心化的系统信任并不是问题, 可是我们需要解决的是去中心化的问题啊? 解决方案是: 引入外部共识. 

## 从物理世界寻找新的信任根

在设计TEA Project之初, 那时候Pandemic还没有开始. 我参加了不少硅谷的技术聚会, 听了很多十分独特的共识算法的idea. 的确他们都是极为聪明的人. 我在算法和数据功力方面显然无法和他们媲美. 但是我发现了他们的共同的理论基础都是基于数学. 所有这些都无法避免的需要使用巨大的计算或者存储或者网络资源的消耗作为代价. 当然, 他们的理由也很充分, 因为计算能力有摩尔定律保佑下会突飞猛进. 今天难以实现的计算规模未来就是小意思. 我并不完全反对这个预测, 但是如果把能耗算进去, 可能就不能突飞猛进了. 任何逻辑资源的消耗最终落到物理资源上, 就无解了. 想到这里, 我于是习惯性地告诫自己, 打破常规. 从盒子外面看问题. 既然物理资源成为限制, 那么能不能就利用物理资源呢? 一旦思路扩宽了, 一下子就天马行空不可收拾. 最终建立起来现在的三个基本信任根的二层协议　也就是TEA Project的最最基本的逻辑原理.

# 全新的信任根造就全新共识思路: 可信硬件, 可信时间, 和区块链

共识算法之所以这么复杂，很大程度上是因为需要假设网络对方是不可信的。所以需要通过各种各样的验证来确保逻辑安全。 如果每一个节点对于每一个信息的处理都需要这样复杂的审查，那么效率自然很低。这就好像我们经常看到的谍战剧里面的剧情类似。如果一个需要频繁的协作出块这类的实时性要求很高的逻辑，每次都像间谍接头对暗号的方式来通讯，互相猜忌闪躲就效率太低了。但是你要知道这些间谍如果回到自己的情报局总部开会的时候就没有这些麻烦了。他们可以直接讨论交流而不是对听到的每一句话都去做反间谍筛查。这就是因为他们的间谍总部大楼就是一个安全屋。能够通过层层检查进入这个安全屋的都是可信的节点。我们就是同样的思路，我们通过一个外部的信任根来进行安全验证。如果通过了才可以得到认证后加入这个网络，这样对于有证书在网络内部的节点而言，只需要判断证书可信就可以达成信任交流。 这个外部硬件可信根我们似乎用的是Trusted computing，也就是可信计算技术。这里面最主要的一个硬件就是TPM芯片。具体的技术细节可以参考相关章节。

有了可信硬件的保护，已经可以极大的提高信息处理效率了。为了可以让网络对端来验证这个证书，就需要一个可信的存证机制。在中心化的系统中这个不是问题，但是对于一个去中心化的系统，这个存证系统就是区块链最擅长的了。所以我们需要一个区块链，不过和几乎所有其他的区块链平台的不同之处在于我们的区块链不是用来运行用户的商业逻辑的，而只用于进行可信计算必须的数据存证。进行可信验证并不需要巨大的运量和存储，所以对于任何一个普通区块链来说是足以胜任的了。在TEAProject中，区块链的职责就相当于安全局门口的安检人员，他们的职责简单但是十分可靠。这正好是区块链最擅长的地方，所谓物尽其用。

有了区块链和可信硬件，还缺最后一个可以取代共识算法的重要因素，也就是我们这个宇宙最稳定可信的而且不可逆的物理量 -- 时间。

很多商业逻辑都是和时间密切相关的，很多网络攻击也同样是针对这个重要参数进行的。常见的双花攻击和抢跑攻击，他们都是利用了时间验证很困难的机制。很多区块链共识机制的设计复杂度就是为了减少此类攻击从而诞生的。人类其实已经可以很精确的得到时间，并利用它来满足日常生活的需求。最常见的就是每个人都用的GPS，就是使用卫星上的原子钟的时间来计算自己在地球上的位置。这种技术也同样用于共识算法，比如Google Spanner数据库就是一个例子。他们使用每个数据中心的原子钟和GPS信号来进行基于时间的同步，使得各个数据中心同步数据的时候可以处理冲突。TEA Project也是使用同样的原理，只不过每个节点不需要配置原子钟，只需要有GPS接收器就可以了。说到这里，可能有一个很明显的漏洞： Google是中心化的，他们自然可以相信来自于另外一个数据中心给出的精准时间，但是TEA project是去中心化的，我怎么知道对方有没有捏造一个时间来作弊？ 这个问题的解决又回到可信计算了。 可信计算的硬件不仅仅可以用于检查节点上运行的软件，也可以用于检查上面的硬件包括GPS硬件。这样如果节点试图去捏造GPS的数据，那么一来TPM 会检测到改动并报告，另一方面其他节点也会根据TPM提供的数据和GPS时间戳来检查其合理性。 这样的检查的成本远低于传统共识算法的成本。

有了可信硬件，可信时间和区块链， TEA Project就可以在一个低成本低能耗低区块链上构建高效率大规模的去中心化的云计算平台给Dapp使用了.为了区别于这种新行的运行在TEA平台上的DApp， 我们起了一个新名字：TApp。

# TApp的三层去中心化技术栈
相对于基于以太坊的智能合约的DApp, TApp从技术架构上更加接近于传统的互联网应用.这就使得对于传统的商业逻辑和云计算开发者而言,更加容易适应和移植. 也是由于同样的原因, 原本很难在智能合约上做到完全去中心化的DApp可以变成适应复杂的商业逻辑的Rich DApp,也就是我们说的TApp.

我们可以沿用传统的云计算应用到三层结构来命名TApp的三层架构, 这样就分为前端,后端和数据库. 但是这三个层都和云计算的对应层有很大技术区别.

## 前端
以Web应用为例, 所有的前端代码都是存储在IPFS上以唯一到CID作为标识. 这样的话就不再需要一个常见的Web 服务器来用于存储和feed前端代码了. 这样就实现了完全的去中心化了. 因为IPFS自身是完全去中心化的存储. 只要有一个CID,你的前端代码就一定可以加载得到. 

由于没有了传统的网站服务器, 原先被广泛认同的域名也不再重要. 甚至于HTTPS也不再是必须的, 尽管很多浏览器会对http提出警告. 那么带来的问题就是从哪里获得CID,如何知道这个CID就是某个TApp的最新版本. 这个问题的答案和此前存储可信计算的存证数据的解决方案是一样的, 使用一层的区块链.

前端和一层区块链是用直接的API联系的. 如果只是简单地仅涉及到区块链的操作, 就不需要跑到后端APi而是直接和一层区块链API交互执行. 只有需要数据库的操作才会用得到后端.

## 后端
前端因为是从IPFS加载的静态资源, 所有的动态数据的查询和用户指令都需要后端来处理. 这里的后端就是单纯的API, 不再提供前端静态资源下载服务了.

这里的API分为两个大类. 一类是查询, 一类是命令.

查询是不会修改应用的状态的(俗称数据库),命令就类似于智能合约中的交易Transaction, 是用于改变状态的.

查询操作不需要排序和等待,可以直接从数据库层查询. 命令操作就复杂很多, 因为设计到对数据库的修改, 这些命令需要根据精确时间排序. 这里涉及到TEA的一个PoTS算法. 这个算法用于保证Host数据库服务的多个Replica节点可以分别更新自身的数据状态但是不会发生冲突. 从而实现了不需要共识的共识机制. 这样才可以达到去中心化的高性能商业应用.

## 最终一致性的数据库和强一致性的状态机

根据具体的商业逻辑的需求, 很多的应用事实上是存在两个状态大类. 一个是强一致性的, 比如涉及到资金和账务的. 另一大类的允许短时间不一致的业务逻辑, 比如TeaParty示例应用中的Messages使用的CRDT数据库. 

传统的互联网应用都通常状态管理为数据库, 所以我们也使用数据库这样的名字是为了符合现有习惯. 不过事实上我们是区分两个不同需求的状态类型的. 所以严格地说一个叫CRDT数据库, 一个叫强一致性状态机. 比如我们最早推出的TApp就采用完全内存存储的Patracia Tries的数据结构作为状态存储. 这个显然并不是数据库,倒是和以太坊的状态机十分接近. 所以严格地说, 状态机这个概念更加合理.

状态机的复杂之处在于多节点之间的状态同步. 因为我们不希望使用传统区块链的共识算法来做到强一致性, 那么保证交易顺序在所有Replica一致就变成最重要的工作. 我们做到这一点是依靠来自GPS卫星上的原子钟提供的精准时间. 这个时间在TPM可信芯片的监督下得到承认, 并作为最终所有replica排序的依据. 由于时间在我们这个宇宙是稳定的, 因此就可以实现各个Replica实现非共识算法的强一致性.

根据CAP不可能三角准则为了实现强一致性而且保证去中心化,那么就必须在时效上作出一些妥协. 区块链就是这种妥协的典型例子. 这也是区块链普遍被认为效率很低的原因. 

TEA由于使用了可以硬件作证的来自导航卫星的时间戳, 各个节点可以在极小的同步代价下实现连续地状态更新和同步. 之所以是连续的, 是指TEA的状态机没有区块的概念. 并不需要每隔一段时间所有节点对区块达成共识. 但是为了保证大多数Replications可以同步到到一致的状态, 需要有一个短暂的排队等待期. 让准备接受处理的Command (或者叫Transaction交易)在这里接受缓冲排队. 当超过半数的Replications都不再能够调整顺序的时候这些交易才会被送去状态机进行处理. 一旦处理结果被提交就是最终一致性的. 这个算法TEA内部叫做传送带算法. 同样使用物理时间来做分片和大容量处理的典型案例就是Google Spanner. 

对于允许短时间不一致但是最终可以取得一致的业务需求, 最理想的就是CRDT算法了. CRDT(Conflcit free replication data type)可以让不同的Replications之间进行无冲突的合并并最终达成全网一致性. 事实上绝大多数的业务逻辑都是可以容忍短时间的不一致从而达到去中心化和效率兼顾的. 典型的例子就是Google Doc. 

在我们的示例应用TEA Party中, 除了需要计费的逻辑之外,所有的应用逻辑(比如说消息列表)都是使用CRDT存储在OrbitDb的数据库中的. 这样各自矿工提供的Host节点不需要和其他矿工节点达成强一致性, 一样可以保证用户可以快速的互相交流. 如果用户细心,也许会注意到有一些消息发送出来之后被发送者欠费被撤回的时候会有短暂不一致发生. 有一些节点立刻就删掉这条撤回信息,有些节点由于网络延迟会稍微晚一些. 事实上我们使用的所有基于互联网云计算的即时消息应用在撤回已发送消息的时候也都是这样的. 所以大家已经习惯了.

# TEA App应用开发者需要做的事情
TEA Project的目的就是为了帮助熟悉互联网应用的开发者可以以很小的代价开发丰富的去中心化的应用. 这里有两个关键词: 一个是“丰富”, 一个是“去中心化”.

丰富是相对于现在的区块链智能合约类型的应用而言的. 很显然现在互联网应用的丰富程度远超区块链应用. 如同前面提到的计算器和iPad的区别. 

去中心化是相对于中心化的云计算平台而言的. 因为TEA上的应用不需要开发者自己去负责租用主机维护主机接受中心化的平台盘剥. 

## TEA仍然是三层结构
前端后端和数据库是最典型的互联网商业应用的结构. 尽管今年类有各种的Serverless function as a service框架来使得Backend as a service. 但是基本结构仍然是这样定义的. 对于TApp的开发者而言是一模一样的.

开发者需要使用html/js/css 语言, 自己喜欢的前端框架完成前端的代码. 把所有这些编译好的静态资源打包存储到IPFS上面获得一个CID. 这个CID就是你的用户从TEA节点或者任何IPFS节点下载你的前端代码到浏览器的Key.

开发者需要使用任何可以便已成为Wasm的计算机语言编写后端逻辑. 这些后端逻辑接近于传统互联网应用开发中的REST API Handler. 如果这些请求处理中需要查询和修改数据库层, 那么就需要数据库的存储过程的参与了.

开发者开发数据库存储过程是运行在状态机上的交易处理代码. 状态机只接受很少几个OPCode, 所以开发者需要自己开发Transaction handler来解读Transaction内部, 翻译成为这几个OPCode来改变状态机的状态. 与这一层对应的传统应用开发就相当于SQL语言的存储过程.

## Rust语言和WebAssembly
TEA的示例应用开发使用了JS和Rust两种语言. 最终运行编译目标是WebAssembly. 也就是说不一定非要使用Rust语言, 而是任何可以最终变异成为WebAsembly的高级语言都可以用于TEA应用开发. 这一点随后希望社区的贡献者贡献更多各种语言的示例应用.

## 无需部署, 只需要吸引矿工来Host
TEA是一种不同于互联网商业逻辑的全新的生产关系. 参与的各方: 开发者, 矿工, 投资者和消费者, 他们的身份交错混杂, 各自按照自己利益最大化的原则与他人协作生产提供服务达成共赢. 

所以这个部分也许是和互联网应用最大的区别了. 因为TEA是完全去中心化的. 你无法像互联网应用那么自己找台机器或者租亚马逊的云主机来host. 开发者需要做的是把打包好的代码存储到IPFS上, 然后在链上提交这个新版本. 剩下的就是通知和吸引矿工来Host你的应用了. 这里有一个重要的Defi概念叫做Bonding curve我们会有专门的章节来介绍. 

# 开发者与矿工/投资者/消费者的关系

开发者开发应用, 矿工提供硬件Host应用. 只有Host了的应用才可以提供服务.

根据开发者设定的TApp参数, 矿工可以计算自身的收益率来决定是否愿意Host这个应用还是别的. 开发者也可以选择是给固定收益(固定收益模式)给矿工还是和矿工分享收益(分红模式). 前者开发者承担风险, 后者开发者和矿工共担风险. 如果没有矿工愿意Host,那么开发者就需要降低门槛提高分成来吸引矿工. 如果大量的矿工竞争Host你的应用, 那么你可以提高门槛减少收益从而开发者自身利益最大化. 所有这些收益都用Bonding curve实现代码化合约管理.

由于使用了Bonding curve, 开发者不需要自己承担全部开发风险和成本. 开发者可以通过在TEA平台发行Bonding curve代币的方式向投资者募集资金和提前兑现未来收益. 当然, 矿工也可以使用自己的计算资源作为投资参与(分红模式). Bonding curve不同于ICO. 所有的投资和未来的消费者消费收益(利润)都是合约自动管理的. 所有人都是和合约在做交易, 而不是互相做交易. 这是一个典型的Defi模型.

消费者使用应用, 支付费用. 这些费用直接进入Bonding curve的合约, 然后按照预先设定的参数进行分红分配. 

所有应用的代币持币人共享代币数量增长带来的估值增加和红利. 也就是说所有这四方都是共赢的成员. 任何一个自然人都可以拥有一个或者多个角色. 比如一个开发者自己也Host. 矿工用自己的计算资源作为投资就相当于投资人. 一个消费者自己也是投资人等等.

